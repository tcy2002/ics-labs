#######################################################################
# Test for copying block of size 4;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $4, %rdx		# src and dst have 4 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
# Tong Chuyan 520021910934
#
# Describe how and why you modified the baseline code.
# 1. Loop unrolling: the main loop is unrolled to 9 pieces(label loopN).
#    when the remainder is greater than or equal to 9, the loop 
#    continues, otherwise each remainder case is dealt with separately. 
#    I tried 8, 9 and 10 unrolling lengths, and finally confirmed 
#    10 has the lowest CPE and is also within the 1000 bytes limit.
#
# 2. Jump tree for remains: the code snippet followed label JumpTree
#    is designed to jump to different PC for different remainder
#    cases(label FootN). The structure of the tree is the result of
#    serious consideration to attain the highest prediction efficiency.
#    Jump tree structure:
#                              1
#                            ↙   ↘
#                          0       5
#                                ↙   ↘
#                              ↙       ↘
#                            3           7
#                          ↙   ↘       ↙   ↘
#                        2       4   6       8
#    Given that the first test case greatly affects the average, 
#    1 is put on the root.
#
# 3. Avoid load/use hazard: in the main loop, three pieces of 
#    unrolled circle are integrated, so that the mrmovq and rmmovq
#    instructions are not adjacent. In the remains part, two pieces 
#    can't be combined due to the independence of each jump, so the 
#    add operation in one piece is inserted between mrmovq and 
#    rmmovq in the last piece, which acts the same role, but the 
#    first load/use hazard is inevitable.
#
# 4. Other optimizations: useless instructions and unnecessary jmps 
#    are avoided, such as xorq %rax, %rax and jmp Done. the remains
#    part is put after the main loop to avoid additional jmp and ret.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-9, %rdx
	jl JumpTree

Loop0:
	mrmovq 64(%rdi), %r10
	mrmovq 56(%rdi), %r11
	mrmovq 48(%rdi), %r12
	andq %r10, %r10
	jle Loop1
	iaddq $1, %rax
Loop1:	rmmovq %r10, 64(%rsi)
	andq %r11, %r11
	jle Loop2
	iaddq $1, %rax
Loop2:	rmmovq %r11, 56(%rsi)
	andq %r12, %r12
	jle Loop3
	iaddq $1, %rax
Loop3:	rmmovq %r12, 48(%rsi)

	mrmovq 40(%rdi), %r10
	mrmovq 32(%rdi), %r11
	mrmovq 24(%rdi), %r12
	andq %r10, %r10
	jle Loop4
	iaddq $1, %rax
Loop4:	rmmovq %r10, 40(%rsi)
	andq %r11, %r11
	jle Loop5
	iaddq $1, %rax
Loop5:	rmmovq %r11, 32(%rsi)
	andq %r12, %r12
	jle Loop6
	iaddq $1, %rax
Loop6:	rmmovq %r12, 24(%rsi)

	mrmovq 16(%rdi), %r10
	mrmovq 8(%rdi), %r11
	mrmovq (%rdi), %r12
	andq %r10, %r10
	jle Loop7
	iaddq $1, %rax
Loop7:	rmmovq %r10, 16(%rsi)
	andq %r11, %r11
	jle Loop8
	iaddq $1, %rax
Loop8:	rmmovq %r11, 8(%rsi)
	andq %r12, %r12
	jle Loop9
	iaddq $1, %rax
Loop9:	rmmovq %r12, (%rsi)

	iaddq $72, %rdi
	iaddq $72, %rsi
	iaddq $-9, %rdx
	jge Loop0
	
JumpTree:
	iaddq $8, %rdx
	jg T1
	je Foot8
	ret
T1:	iaddq $-4, %rdx
	jl T11
	jg T12
	jmp Foot4
T11:	iaddq $2, %rdx
	jl Foot7
	je Foot6
	iaddq $-1, %rdx
	jmp Foot5
T12:	iaddq $-2, %rdx
	jl Foot3
	je Foot2

Foot1:	
	mrmovq 56(%rdi), %r10
	rmmovq %r10, 56(%rsi)
	andq %r10, %r10
Foot2:
	mrmovq 48(%rdi), %r10
	jle P3
	iaddq $1, %rax
P3:	rmmovq %r10, 48(%rsi)
	andq %r10, %r10
Foot3:
	mrmovq 40(%rdi), %r10
	jle P4 
	iaddq $1, %rax
P4:	rmmovq %r10, 40(%rsi)	
	andq %r10, %r10
Foot4:
	mrmovq 32(%rdi), %r10
	jle P5
	iaddq $1, %rax
P5:	rmmovq %r10, 32(%rsi)
	andq %r10, %r10
Foot5:
	mrmovq 24(%rdi), %r10
	jle P6
	iaddq $1, %rax
P6:	rmmovq %r10, 24(%rsi)
	andq %r10, %r10
Foot6:
	mrmovq 16(%rdi), %r10
	jle P7
	iaddq $1, %rax
P7:	rmmovq %r10, 16(%rsi)
	andq %r10, %r10
Foot7:
	mrmovq 8(%rdi), %r10
	jle P8
	iaddq $1, %rax
P8:	rmmovq %r10, 8(%rsi)	
	andq %r10, %r10
Foot8:
	mrmovq (%rdi), %r10
	jle P9
	iaddq $1, %rax
P9:	rmmovq %r10, (%rsi)		
	andq %r10, %r10
	jle Done
	iaddq $1, %rax
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad 2
	.quad -3
	.quad -4
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
